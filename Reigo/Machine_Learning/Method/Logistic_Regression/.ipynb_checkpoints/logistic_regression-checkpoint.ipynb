{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "722b1bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "#显示中文字符\n",
    "plt.rcParams['font.sans-serif']=['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f93365e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17bf7b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5642cc57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bfe57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建数据\n",
    "x,X,y=generate_data(4,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "56912a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic 回归梯度上升优化算法\n",
    "class Logistic_Regression:\n",
    "    def __init__(self,n=10):\n",
    "        self.n=n\n",
    "        self.dimension=2 #x的维度 (x1,x2···)\n",
    "        self.theta=np.ones((self.dimension+1,1))\n",
    "        self.x,self.X,self.y=self.generate_data(self.n,True)\n",
    "        \n",
    "    def train(self):\n",
    "        self.grad_ascent()\n",
    "        self.plot_result()\n",
    "\n",
    "    def grad_ascent(self):\n",
    "        __epoch__ = 10000 #回归圈数\n",
    "        \n",
    "        X=self.X #shape(n,3)\n",
    "        y=self.y #shape(n,1)\n",
    "        theta=self.theta #shape(1,3)\n",
    "\n",
    "        n = X.shape[0]\n",
    "        alpha = 1\n",
    "\n",
    "        for  i in tqdm(range(__epoch__)):\n",
    "            error=self.sigmoid(X@theta)-y #error h(z)-y shape(n,1)\n",
    "            loss0=loss_function(theta,X,y)\n",
    "            theta=theta-alpha*X.T@error   #theta shape(3,1) theta(i+1)=theta(i)-(alpha/n)*加和1~n(h(z)-y)*x\n",
    "            loss1=loss_function(theta,X,y)\n",
    "    \n",
    "            if(loss1-loss0>0):\n",
    "                alpha*=0.5\n",
    "        \n",
    "\n",
    "    def grad_ascent_withPenalty(self,data_matrix, label_mat):\n",
    "        #data_matrix = np.mat(data_arr)  # convert to NumPy matrix\n",
    "        #label_vector = np.mat(label_arr).transpose()  # convert to NumPy matrix\n",
    "        m, n = np.shape(data_matrix)\n",
    "        alpha = 1\n",
    "        lam=np.exp(-2)\n",
    "        weights = np.ones((n, 1))\n",
    "        for  p in range(max_cycles):\n",
    "            error=sigmoid(data_matrix@weights)-label_mat\n",
    "            loss0=loss_function(m,weights,data_matrix,label_mat)\n",
    "            weights=(1-alpha*lam/m)*weights-alpha*data_matrix.T@error\n",
    "            loss1=loss_function(m,weights,data_matrix,label_mat)\n",
    "            if(loss1-loss0>0):\n",
    "                alpha*=0.5\n",
    "        return weights\n",
    "    \n",
    "    \n",
    "    def generate_data(self,n,isNaive=True):\n",
    "        #function:\n",
    "        # 生成两组符合高斯分布的数据和不同标签\n",
    "        #Param:\n",
    "        # number:数据集中点的个数\n",
    "        # naive:选择生成的数据是否满足朴素贝叶斯假设\n",
    "        #Return:\n",
    "        # train_x x坐标 [[-1,2],[2,0].···] \n",
    "        # x_matrix X矩阵 在train_x的基础上 在最后一列加一列1\n",
    "        # train_y y标签 [1,0,1,1,1，···]\n",
    "\n",
    "\n",
    "        number=int(number)\n",
    "        # 类别为0的数据点数\n",
    "        number0 = number//2\n",
    "        means0 = [-0.6, -0.4]\n",
    "        # 类别为1的数据点数\n",
    "        number1 = number - number0\n",
    "        means1 = [0.6, 0.4]\n",
    "        # 随机变量方差与两个维度的协方差\n",
    "        variance = 0.2#0.2\n",
    "        cov = 0.5 #0.5\n",
    "        train_x = np.zeros((number, 2))\n",
    "        train_y = np.zeros((number, 1))\n",
    "\n",
    "        # 满足朴素贝叶斯假设(两个维度的协方差矩阵除对角线外均为0)\n",
    "        if isNaive:\n",
    "            train_x[:number0, :] = np.random.multivariate_normal(means0, [[variance, 0], [0, variance]], number0)\n",
    "            train_x[number0:, :] = np.random.multivariate_normal(means1, [[variance, 0], [0, variance]], number1)\n",
    "            train_y[:number0] = 0\n",
    "            train_y[number0:] = 1\n",
    "        # 不满足朴素贝叶斯假设(两个维度的协方差矩阵除对角线外为cov)\n",
    "        else:\n",
    "            train_x[:number0, :] = np.random.multivariate_normal(means0, [[variance, cov], [cov, variance]], number0)\n",
    "            train_x[number0:, :] = np.random.multivariate_normal(means1, [[variance, cov], [cov, variance]], number1)\n",
    "            train_y[:number0] = 0\n",
    "            train_y[number0:] = 1\n",
    "\n",
    "        # 生成数据矩阵\n",
    "        x_matrix = np.ones((number, 3))\n",
    "        x_matrix[:,0:2]=train_x\n",
    "        return train_x, x_matrix, train_y\n",
    "    \n",
    "    def load_data_set(self):\n",
    "        # 创建两个列表\n",
    "        data_mat = []\n",
    "        label_mat = []\n",
    "        fr = open('testSet.txt')\n",
    "        for line in fr.readlines():\n",
    "            # 对当前行去除首尾空格，并按空格进行分离\n",
    "            line_arr = line.strip().split()\n",
    "            data_mat.append([1.0, float(line_arr[0]), float(line_arr[1])])\n",
    "            label_mat.append(int(line_arr[2]))\n",
    "        return data_mat, label_mat\n",
    "    \n",
    "    def sigmoid(self,x):\n",
    "        return 1.0 / (1 + np.exp(-x))\n",
    "\n",
    "    def loss_function(self,theta,X,y):\n",
    "        #param: \n",
    "        # theta:(w,b)参数\n",
    "        # X: 数据集加一列1\n",
    "        # y: 标签\n",
    "        #return:\n",
    "        # Loss: 损失函数 一个值\n",
    "        \n",
    "        #L(w)=(-1/n)*求和1~n(y*ln(h(z)+(1-y)*ln(1-h(z)))\n",
    "        #z=w1x1+w2x2+···wkxk+b\n",
    "        #h(z)=sigmoid(z)\n",
    "        \n",
    "        n=X.shape[0] #数据量\n",
    "        z=X@theta #shape(n,1)\n",
    "        hz=self.sigmoid(z) #shape(n,1)\n",
    "        return (-1.0/n)*np.sum(np.multiply(y,np.log(hz))+np.multiply((1-y),np.log(1-hz)))\n",
    "    \n",
    "    def score(self,theta,x_matrix,y_mat):\n",
    "        all_datanum=x_matrix.shape[0]\n",
    "        count_right=0\n",
    "        classify_matrix=x_matrix@theta\n",
    "        for i in range(all_datanum):\n",
    "            if classify_matrix[i]>0 and y_mat[i]==1:\n",
    "                count_right+=1\n",
    "            elif classify_matrix[i]<0 and y_mat[i]==0:\n",
    "                count_right+=1\n",
    "        right_rate=float(count_right)/all_datanum\n",
    "        return right_rate\n",
    "    \n",
    "    def plot_point(self):\n",
    "        x=self.x\n",
    "        X=self.X\n",
    "        y=self.y\n",
    "        theta=self.theta\n",
    "        \n",
    "        n=self.x.shape[0]\n",
    "        \n",
    "        plt.plot(x_trainset[0:n//2,0], x_trainset[0:n//2,1], color='g', linestyle='', marker='o',markersize=2, label=u\"正例\")\n",
    "        plt.plot(x_trainset[n//2:n,0], x_trainset[n//2:n,1], color='r', linestyle='', marker='o',markersize=2, label=u\"反例\")\n",
    "        plt.legend(loc='upper left')\n",
    "        \n",
    "    def plot_decision_surface(self):\n",
    "        pass\n",
    "        \n",
    "    def plot_result(self):\n",
    "        plt.title(\"训练集 满足贝叶斯的分布 无正则项\")\n",
    "        \n",
    "        fig=plt.figure()\n",
    "        plt.show()\n",
    "    def plot_3D(self,train_x, train_y, coefficient):\n",
    "        # train_x: 训练集数据\n",
    "        # train_y: 训练集数据结果\n",
    "        # coefficient:决策面系数\n",
    "\n",
    "        ax = Axes3D(plt.figure())\n",
    "        ax.scatter(train_x[:, 0], train_x[:, 1], train_x[:, 2], c=np.squeeze(train_y), cmap=plt.cm.Spectral)\n",
    "        real_x = np.arange(np.min(train_x[:, 0]), np.max(train_x[:, 0]), 1)\n",
    "        real_y = np.arange(np.min(train_x[:, 1]), np.max(train_x[:, 1]), 1)\n",
    "        real_x, real_y = np.meshgrid(real_x, real_y)\n",
    "        real_z = coefficient[0][0,0] + coefficient[1][0,0] * real_x + coefficient[2][0,0] * real_y\n",
    "        ax.plot_surface(real_x, real_y, real_z, rstride=1, cstride=1)\n",
    "        ax.set_zlim(np.min(real_z) - 10, np.max(real_z) + 10) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f019bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Logistic_Regression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd1f63b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d5667b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0bb6cc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#查看数组a1的属性\n",
    "def check(a1):\n",
    "    print(a1)  \n",
    "    print(\"数据类型\",type(a1))           #打印数组数据类型  \n",
    "    print(\"数组元素数据类型：\",a1.dtype) #打印数组元素数据类型  \n",
    "    print(\"数组元素总数：\",a1.size)      #打印数组尺寸，即数组元素总数  \n",
    "    print(\"数组形状：\",a1.shape)         #打印数组形状  \n",
    "    print(\"数组的维度数目\",a1.ndim)      #打印数组的维度数目\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
